{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3257f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\?\\\\D:\\\\Projects\\\\Calm_ISO\\\\5h_Injection\\\\ISO_Total'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(fr'\\\\?\\D:\\Projects\\LocProt\\ISH_IF\\IF_ISH_Fig3')\n",
    "\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "92ac41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of paths with labeled images\n",
    "\n",
    "def get_labeled_puncta_path(mNRA_Red, SubSET=None):\n",
    "\n",
    "    WORD1 = str(mNRA_Red).lower()\n",
    "    WORD2 = str(SubSET).lower()\n",
    "\n",
    "    input_dir = fr'\\\\?\\D:\\Projects\\LocProt\\ISH_IF\\IF_ISH_Fig3'\n",
    "\n",
    "    labeled_path_list = []\n",
    "\n",
    "    # Loop through all directories and subdirectories inside the input directory\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # Loop through all files in the current directory\n",
    "        for file in files:\n",
    "            # Check if the file has an _info.txt extension and starts with the folder name\n",
    "            if \"_info.txt\" in file and file.startswith(os.path.basename(root)):\n",
    "                # Read the file content and convert it to lowercase\n",
    "                with open(os.path.join(root, file), \"r\") as f:\n",
    "                    file_content = f.read().lower()\n",
    "\n",
    "                # Check if WORD1 and WORD2 are in the file content\n",
    "                if WORD1 in file_content and WORD2 in file_content:\n",
    "                # if WORD1 in file_content:\n",
    "                    # Append the folder path to the list\n",
    "                    labeled_path_list.append(root)\n",
    "\n",
    "    # Return the list of paths+\n",
    "    return labeled_path_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3377ce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_puncta_path_list = get_labeled_puncta_path(\"Ryr2\", \"WT\")\n",
    "\n",
    "len(labeled_puncta_path_list)\n",
    "# labeled_puncta_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6c501a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from skimage import io, util, morphology\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "input_dir = fr'\\\\?\\D:\\Projects\\LocProt\\ISH_IF\\IF_ISH_Fig3'\n",
    "os.chdir(input_dir)\n",
    "\n",
    "def Puncta_Processing(path_list, mRNA1, SubSet=None):\n",
    "       \n",
    "    df = pd.DataFrame()\n",
    "    df_red_to_nuclei_distances_raw = pd.DataFrame()\n",
    "    df_red_to_nuclei_distances_normalized = pd.DataFrame()\n",
    "    \n",
    "    df_random_red_to_nuclei_distances_raw = pd.DataFrame()\n",
    "    df_random_red_to_nuclei_distances_normalized = pd.DataFrame()\n",
    "   \n",
    "    df_membrane_to_nuclei_distances_raw = pd.DataFrame()     \n",
    "    df_membrane_to_nuclei_distances_normalized = pd.DataFrame()\n",
    "\n",
    "    WORD1 = str(mRNA1) \n",
    "    WORD2 = str(SubSet)\n",
    "    \n",
    "    for path in path_list:\n",
    "        min_distances = []  # list to store min distances\n",
    "        min_distances_normalized = []  # list to store normalized min distances\n",
    "        red_to_nuclei_distances = {}        \n",
    "\n",
    "        start_time = time.time()  # start the timer\n",
    "        \n",
    "        mRNA1_Name_SubSET_mask_path = os.path.join(path, 'Segmented', f'Labeled_{WORD1}.tif')\n",
    "        Body_SubSET_mask_path = os.path.join(path, 'Segmented', 'Masked_Body_image.tif')\n",
    "        Nuclei_SubSET_mask_path = os.path.join(path, 'Segmented', 'Masked_Nuclei_image.tif')\n",
    "        Cytosol_SubSET_mask_path = os.path.join(path, 'Segmented', 'Masked_Cytosol_image.tif')\n",
    "        mRNA1_Name_SubSET_mask_path_bool = os.path.join(path, 'Segmented', f'Masked_{WORD1}_filtered_image.tif')\n",
    "\n",
    "        with open(os.path.join(path, os.path.basename(path) + '_info.txt'), 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        pattern = r\"XYZCalibration\\(um\\/vox\\):(\\d+\\.\\d+),(\\d+\\.\\d+),(\\d+\\.\\d+):\"\n",
    "        match = re.search(pattern, text)\n",
    "\n",
    "        if match:\n",
    "            x_dim = float(match.group(1))\n",
    "            y_dim = float(match.group(2))\n",
    "            z_dim = float(match.group(3))\n",
    "        else:\n",
    "            print(\"No match found.\")  \n",
    "\n",
    "        voxel_dims = (z_dim, y_dim, x_dim)\n",
    "        \n",
    "        # Load the binary images\n",
    "        red_img = tifffile.imread(mRNA1_Name_SubSET_mask_path) # Centroids with Zero coordinates\n",
    "        nuclei_img = tifffile.imread(Nuclei_SubSET_mask_path)\n",
    "        cytosol = util.img_as_bool(tifffile.imread(Cytosol_SubSET_mask_path))\n",
    "        mRNA1_bool = util.img_as_bool(tifffile.imread(mRNA1_Name_SubSET_mask_path_bool))\n",
    "        \n",
    "        Body_bool = util.img_as_bool(tifffile.imread(Body_SubSET_mask_path))\n",
    "        dilated_Body_bool = morphology.binary_dilation(Body_bool)\n",
    "        edges_Body_bool = np.logical_xor(Body_bool, dilated_Body_bool)\n",
    "#         tifffile.imwrite('edges_Body_bool.tif', edges_Body_bool)\n",
    "        Nuclei_bool = util.img_as_bool(nuclei_img)\n",
    "        \n",
    "        # Find the centroids of the red puncta\n",
    "        red_labels = label(red_img)\n",
    "        red_props = regionprops(red_labels)\n",
    "        \n",
    "        # Extract the centroids and store them in a list\n",
    "        red_centroids = []\n",
    "        for prop in red_props:\n",
    "            z, y, x = prop.centroid\n",
    "            centroid = (z * z_dim, y * y_dim, x * x_dim)\n",
    "            red_centroids.append(centroid)\n",
    "        \n",
    "        # Get the coordinates of all True values in Nuclei and Edges of Cell Body\n",
    "        coords_Nuclei = np.argwhere(Nuclei_bool == True)\n",
    "        coords_edges_Body = np.argwhere(edges_Body_bool == True)  \n",
    "        \n",
    "        # Scale the coordinates to physical units using the voxel dimensions\n",
    "        coords_Nuclei_physical = coords_Nuclei * voxel_dims\n",
    "        coords_edges_Body_physical = coords_edges_Body * voxel_dims\n",
    "        \n",
    "        # Initialize the NearestNeighbors object with n_neighbors=1 (find the nearest neighbor) \n",
    "        nn1 = NearestNeighbors(n_neighbors=1, algorithm='kd_tree', metric='euclidean')\n",
    "        nn1.fit(coords_Nuclei_physical) #mRNA_Name to Nuclei fit\n",
    "        distances, indices = nn1.kneighbors(coords_edges_Body_physical)\n",
    "        temp_df3 = pd.DataFrame({'z': coords_edges_Body_physical[:, 0], 'y': coords_edges_Body_physical[:, 1], 'x': coords_edges_Body_physical[:, 2], 'distance': distances.flatten()}) # Create a pandas dataframe to store the results\n",
    "        max_distance_from_nuclei = temp_df3['distance'].max() \n",
    "        \n",
    "        min_distances_membrane_normalized = temp_df3['distance'] / max_distance_from_nuclei\n",
    "        df_min_distances_membrane_normalized = pd.DataFrame(min_distances_membrane_normalized)\n",
    "        df_min_distances_membrane_normalized.columns = [os.path.basename(path)]\n",
    "#         df_min_distances_membrane_normalized = pd.DataFrame(min_distances_membrane_normalized, columns=[os.path.basename(path)])\n",
    "        df_membrane_to_nuclei_distances_normalized = pd.concat([df_membrane_to_nuclei_distances_normalized, df_min_distances_membrane_normalized], axis=1)\n",
    "        median_distance_membrane_normalized = np.quantile(min_distances_membrane_normalized, 0.5)\n",
    "\n",
    "        min_distances_membrane_raw = temp_df3['distance']\n",
    "        df_min_distances_membrane_raw = pd.DataFrame(min_distances_membrane_raw)\n",
    "        df_min_distances_membrane_raw.columns = [os.path.basename(path)]\n",
    "        df_membrane_to_nuclei_distances_raw = pd.concat([df_membrane_to_nuclei_distances_raw, df_min_distances_membrane_raw], axis=1)\n",
    "        median_distance_membrane_raw = np.quantile(min_distances_membrane_raw, 0.5)\n",
    "\n",
    "        # Calculate distances from red centroids to the nearest nuclei pixel\n",
    "        if red_centroids and len(coords_Nuclei_physical) > 0:\n",
    "            red_centroids_array = np.array(red_centroids)\n",
    "            nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(coords_Nuclei_physical)\n",
    "            distancesNN, indices = nbrs.kneighbors(red_centroids_array)\n",
    "\n",
    "            min_distances = [] # list to store min distances\n",
    "            min_distances_normalized = [] # list to store min distances            \n",
    "            \n",
    "            for i, red_coord in enumerate(red_centroids):\n",
    "                nuclei_coord = coords_Nuclei_physical[indices[i][0]]\n",
    "                min_distance = distancesNN[i][0]\n",
    "                red_to_nuclei_distances[red_coord] = {'nuclei_coordinates': tuple(nuclei_coord), 'distance': min_distance}\n",
    "\n",
    "                min_distances.append(min_distance) # append min distance to the list\n",
    "                min_distances_normalized.append(min_distance / max_distance_from_nuclei) # append min distance to the list\n",
    "\n",
    "            # Calculate the median for min_distances and min_distances_normalized for the current path\n",
    "            median_distance_raw = np.quantile(min_distances, 0.5)\n",
    "            median_distance_normalized = np.quantile(min_distances_normalized, 0.5)\n",
    "\n",
    "            # create a DataFrame with min distances\n",
    "            df_min_distances = pd.DataFrame(min_distances, columns=[os.path.basename(path)])\n",
    "            df_red_to_nuclei_distances_raw = pd.concat([df_red_to_nuclei_distances_raw, df_min_distances], axis=1) # concatenate along the column\n",
    "            \n",
    "            df_min_distances_normalized = pd.DataFrame(min_distances_normalized , columns=[os.path.basename(path)])\n",
    "            df_red_to_nuclei_distances_normalized = pd.concat([df_red_to_nuclei_distances_normalized, df_min_distances_normalized], axis=1) # concatenate along the column\n",
    "\n",
    "        # Simulate random distribution of red centroids within the cytosol\n",
    "        cytosol_coords = np.argwhere(cytosol == True)\n",
    "        num_red_centroids = len(red_centroids)\n",
    "        random_indices = np.random.choice(range(len(cytosol_coords)), num_red_centroids)\n",
    "        random_cytosol_coords = cytosol_coords[random_indices]\n",
    "        random_cytosol_coords_physical = random_cytosol_coords * voxel_dims\n",
    "       \n",
    "        # Calculate distances from random centroids to the nearest nuclei pixel\n",
    "        if random_cytosol_coords_physical.size and len(coords_Nuclei_physical) > 0:\n",
    "            nbrs_random = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(coords_Nuclei_physical)\n",
    "            distances_random, indices_random = nbrs_random.kneighbors(random_cytosol_coords_physical)\n",
    "            \n",
    "            min_distances_random = distances_random.flatten()\n",
    "            min_distances_random_normalized = min_distances_random / max_distance_from_nuclei\n",
    "            min_distances_random_raw = min_distances_random\n",
    "            \n",
    "            # Calculate the median for min_distances_random_normalized for the current path\n",
    "            median_distance_random_normalized = np.quantile(min_distances_random_normalized, 0.5)\n",
    "            median_distances_random_raw = np.quantile(min_distances_random_raw, 0.5)\n",
    "            \n",
    "            # create a DataFrame with normalized random min distances\n",
    "            df_min_distances_random_normalized = pd.DataFrame(min_distances_random_normalized, columns=[os.path.basename(path)])\n",
    "            df_random_red_to_nuclei_distances_normalized = pd.concat([df_random_red_to_nuclei_distances_normalized, df_min_distances_random_normalized], axis=1)  # concatenate along the column\n",
    "            df_min_distances_random_raw = pd.DataFrame(min_distances_random_raw, columns=[os.path.basename(path)])\n",
    "            df_random_red_to_nuclei_distances_raw = pd.concat([df_random_red_to_nuclei_distances_raw, df_min_distances_random_raw], axis=1)  # concatenate along the column\n",
    "\n",
    "#             df_temp['Half_Dist_random_{WORD1}_distance_to_nuclei_{WORD2}_normalized'] = median_distance_random_normalized\n",
    "            \n",
    "        # Calculate and add the volume of the Body mask to df1\n",
    "        puncta_red_total = len(red_centroids)\n",
    "        \n",
    "        voxel_volume = x_dim * y_dim * z_dim  # Calculate the volume of a single voxel\n",
    "        cytosol_volume = np.sum(cytosol) * voxel_volume\n",
    "        nuclear_volume = np.sum(Nuclei_bool) * voxel_volume\n",
    "        body_volume = np.sum(Body_bool) * voxel_volume\n",
    "        nuclear_mRNA_volume = np.sum(mRNA1_bool * Nuclei_bool) * voxel_volume\n",
    "        cytosol_mRNA_volume = np.sum(mRNA1_bool * cytosol) * voxel_volume\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            f'Puncta_absolute_{WORD1}_{WORD2}': [puncta_red_total],\n",
    "            f'Puncta_Normalized_{WORD1}_{WORD2}': [puncta_red_total / cytosol_volume],\n",
    "            f'Nuclear_mRNA_Volume_Normalized_{WORD1}_{WORD2}': [nuclear_mRNA_volume / nuclear_volume],\n",
    "            f'Cytosol_mRNA_Volume_Normalized_{WORD1}_{WORD2}': [cytosol_mRNA_volume / cytosol_volume],\n",
    "            f'Cytosol_Volume_{WORD1}_{WORD2}': [cytosol_volume],\n",
    "            \n",
    "            f'Half_Dist_membrane_distance_to_nuclei_{WORD2}_raw': [median_distance_membrane_raw],\n",
    "            f'Half_Dist_membrane_distance_to_nuclei_{WORD2}_normalized': [median_distance_membrane_normalized],\n",
    "\n",
    "            f'Half_Dist_{WORD1}_distance_to_Nuclei_{WORD2}_raw': [median_distance_raw],\n",
    "            f'Half_Dist_{WORD1}_distance_to_Nuclei_{WORD2}_normalized': [median_distance_normalized],\n",
    "            \n",
    "            f'Half_Dist_random_{WORD1}_distance_to_nuclei_{WORD2}_raw': [median_distances_random_raw],            \n",
    "            f'Half_Dist_random_{WORD1}_distance_to_nuclei_{WORD2}_normalized': [median_distance_random_normalized],\n",
    "\n",
    "            \"path\": path\n",
    "        })\n",
    "\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "        \n",
    "        end_time = time.time() # record end time\n",
    "        elapsed_time = end_time - start_time # calculate elapsed timeCalm1\n",
    "\n",
    "        print(f\"Processed {file} in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    df.to_csv(f'Puncta_Processing_{WORD1}_to_Nuclei_{WORD2}.csv')       \n",
    "\n",
    "    df_red_to_nuclei_distances_raw.to_csv(fr'{WORD1}_to_Nuclei_Puncta_raw_distances_{WORD2}.csv') \n",
    "    df_random_red_to_nuclei_distances_raw.to_csv(fr'random_{WORD1}_to_Nuclei_Puncta_raw_distances_{WORD2}.csv')     \n",
    "    df_membrane_to_nuclei_distances_raw.to_csv(fr'membrane_{WORD1}_to_Nuclei_Voxel_raw_distances_{WORD2}.csv')     \n",
    "    \n",
    "    df_red_to_nuclei_distances_normalized.to_csv(fr'{WORD1}_to_Nuclei_Puncta_norm_distances_{WORD2}.csv')     \n",
    "    df_random_red_to_nuclei_distances_normalized.to_csv(fr'random_{WORD1}_to_Nuclei_Puncta_norm_distances_{WORD2}.csv')     \n",
    "    df_membrane_to_nuclei_distances_normalized.to_csv(fr'membrane_{WORD1}_to_Nuclei_Voxel_norm_distances_{WORD2}.csv')    \n",
    "    \n",
    "    return df, df_red_to_nuclei_distances_raw, df_red_to_nuclei_distances_normalized, df_random_red_to_nuclei_distances_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843d4eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_puncta_path_list = get_labeled_puncta_path(\"Ryr2\", \"WT\")\n",
    "print(len(labeled_puncta_path_list))\n",
    "Puncta_Ryr2_Fig3_WT, Dist_Ryr2_Fig3_WT, Dist_Norm_Ryr2_Fig3_WT, Dist_Random_Norm_Ryr2_Fig3_WT = Puncta_Processing(labeled_puncta_path_list, \"Ryr2\", \"WT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a119a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
