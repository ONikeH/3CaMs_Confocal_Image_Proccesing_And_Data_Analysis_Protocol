{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a25ea-21b0-4471-bd78-04270d6008b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ae535-defc-49b2-882a-2c6ebcf8be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(fr'\\\\?\\D:\\Projects\\Calm_ISO\\5h_Injection\\ISO_Total')\n",
    "\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344db7f6-4f3d-45bc-8b8d-722ad1336c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of paths with labeled images\n",
    "# mRNA_Red means the mRNA we are centering, mRNA_Green means the mRNA we are surrounding around centers (Red puncta)\n",
    "import os\n",
    "\n",
    "def get_labeled_overlap_path(mNRA_Red, mRNA_Green, SubSET=None):\n",
    "\n",
    "    WORD1 = str(mNRA_Red).lower()\n",
    "    WORD2 = str(mRNA_Green).lower()\n",
    "    WORD3 = str(SubSET).lower()\n",
    "\n",
    "    input_dir = fr'\\\\?\\D:\\Projects\\LocProt\\ISH_IF\\IF_ISH_Fig3'\n",
    "\n",
    "    labeled_path_list = []\n",
    "\n",
    "    # Loop through all directories and subdirectories inside the input directory\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # Loop through all files in the current directory\n",
    "        for file in files:\n",
    "            # Check if the file has an _info.txt extension and starts with the folder name\n",
    "            if \"_info.txt\" in file and file.startswith(os.path.basename(root)):\n",
    "                # Read the file content and convert it to lowercase\n",
    "                with open(os.path.join(root, file), \"r\") as f:\n",
    "                    file_content = f.read().lower()\n",
    "\n",
    "                # Check if WORD1 and WORD2 and WORD3 are in the file content\n",
    "                if WORD1 in file_content and WORD2 in file_content and WORD3 in file_content:\n",
    "                # if WORD1 in file_content and WORD2 in file_content:\n",
    "                    # Append the folder path to the list\n",
    "                    labeled_path_list.append(root)\n",
    "\n",
    "    # Return the list of paths\n",
    "    return labeled_path_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045db3f0-d487-4fef-b73e-5f67f3b7bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_puncta_path_list = get_labeled_puncta_path(\"RnaRyr2\", \"ProtRyr2\", \"WT\")\n",
    "\n",
    "len(labeled_puncta_path_list)\n",
    "# labeled_puncta_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337a762-2452-4063-a4f4-0fb6b9aed2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from skimage import io, util, morphology\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "input_dir = fr'\\\\?\\D:\\Projects\\LocProt\\ISH_IF\\IF_ISH_Fig3'\n",
    "\n",
    "os.chdir(input_dir)\n",
    "\n",
    "def Puncta_Overlap_Processing(path_list, mRNA_Red, mRNA_Green, SubSet=None):\n",
    "    \n",
    "       \n",
    "    # create a df to count red, green and overlaped centroids (puncta)\n",
    "    df = pd.DataFrame()\n",
    "    df_overlap_to_nuclei_distances = pd.DataFrame()\n",
    "    df_overlap_to_nuclei_distances_normalized = pd.DataFrame()\n",
    "    df_random_overlap_to_nuclei_distances_raw = pd.DataFrame()\n",
    "    df_random_overlap_to_nuclei_distances_normalized = pd.DataFrame()\n",
    "    \n",
    "    WORD1 = str(mRNA_Red) # main centroid\n",
    "    WORD2 = str(mRNA_Green) # secondary centroid\n",
    "    WORD3 = str(SubSet)\n",
    "\n",
    "    for path in path_list:\n",
    "        min_distances = []  # list to store min distances\n",
    "        min_distances_normalized = []  # list to store normalized min distances\n",
    "        overlap_to_nuclei_distances = {}\n",
    "        \n",
    "        start_time = time.time()  # start the timer\n",
    " \n",
    "        mRNA1_Name_SubSET_mask_path = os.path.join(path, 'Segmented', f'Labeled_{WORD1}.tif')\n",
    "        mRNA2_Name_SubSET_mask_path = os.path.join(path, 'Segmented', f'Labeled_{WORD2}.tif') \n",
    "        # mRNA2_Name_SubSET_mask_path = os.path.join(path, 'Segmented', f'Masked_{WORD2}_filtered_image.tif') \n",
    "        Body_SubSET_mask_path = os.path.join(path, 'Segmented', 'Masked_Body_image.tif')\n",
    "        Nuclei_SubSET_mask_path = os.path.join(path, 'Segmented', 'Masked_Nuclei_image.tif')\n",
    "        Cytosol_SubSET_mask_path = os.path.join(path, 'Segmented', 'Masked_Cytosol_image.tif')\n",
    "        \n",
    "        with open(os.path.join(path, os.path.basename(path) + '_info.txt'), 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        pattern = r\"XYZCalibration\\(um\\/vox\\):(\\d+\\.\\d+),(\\d+\\.\\d+),(\\d+\\.\\d+):\"\n",
    "        match = re.search(pattern, text)\n",
    "\n",
    "        if match:\n",
    "            x_dim = float(match.group(1))\n",
    "            y_dim = float(match.group(2))\n",
    "            z_dim = float(match.group(3))\n",
    "        else:\n",
    "            print(\"No match found.\")  \n",
    "\n",
    "        voxel_dims = (z_dim, y_dim, x_dim)\n",
    "        \n",
    "        # Load the binary images\n",
    "        red_img = tifffile.imread(mRNA1_Name_SubSET_mask_path) # Centroids with Zero coordinates\n",
    "        green_img = tifffile.imread(mRNA2_Name_SubSET_mask_path) # Centroids with real coordinates\n",
    "        cytosol = util.img_as_bool(tifffile.imread(Cytosol_SubSET_mask_path))\n",
    "        nuclei_img = tifffile.imread(Nuclei_SubSET_mask_path)\n",
    "\n",
    "        overlap_img = red_img*green_img*cytosol\n",
    "        \n",
    "        Body_bool = util.img_as_bool(tifffile.imread(Body_SubSET_mask_path))\n",
    "        dilated_Body_bool = morphology.binary_dilation(Body_bool)\n",
    "        edges_Body_bool = np.logical_xor(Body_bool, dilated_Body_bool)\n",
    "        Nuclei_bool = util.img_as_bool(nuclei_img) \n",
    "        \n",
    "        # Find the centroids of the red puncta\n",
    "        red_labels = label(red_img)\n",
    "        red_props = regionprops(red_labels)\n",
    "\n",
    "        # Extract the centroids and store them in a list\n",
    "        red_centroids = []\n",
    "        for prop in red_props:\n",
    "            z, y, x = prop.centroid\n",
    "            centroid = (z * z_dim, y * y_dim, x * x_dim)\n",
    "            red_centroids.append(centroid)\n",
    "\n",
    "        # Find the centroids of the green puncta\n",
    "        green_labels = label(green_img)\n",
    "        green_props = regionprops(green_labels)\n",
    "\n",
    "        # Extract the centroids and store them in a list\n",
    "        green_centroids = []\n",
    "        for prop in green_props:\n",
    "            z, y, x = prop.centroid\n",
    "            centroid = (z * z_dim, y * y_dim, x * x_dim)\n",
    "            green_centroids.append(centroid)   \n",
    "            \n",
    "        # Find the centroids of the overlap puncta\n",
    "        overlap_labels = label(overlap_img)\n",
    "        overlap_props = regionprops(overlap_labels)\n",
    "\n",
    "        # Extract the centroids and store them in a list\n",
    "        overlap_centroids = []\n",
    "        for prop in overlap_props:\n",
    "            z, y, x = prop.centroid\n",
    "            centroid = (z * z_dim, y * y_dim, x * x_dim)\n",
    "            overlap_centroids.append(centroid)   \n",
    "                \n",
    "        # Get the coordinates of all 255 values in array1 and array2\n",
    "        coords_Nuclei = np.argwhere(Nuclei_bool == True)\n",
    "        coords_edges_Body = np.argwhere(edges_Body_bool == True)  \n",
    "        \n",
    "        # Scale the coordinates to physical units using the voxel dimensions\n",
    "        coords_Nuclei_physical = coords_Nuclei * voxel_dims\n",
    "        coords_edges_Body_physical = coords_edges_Body * voxel_dims\n",
    "        \n",
    "        # Initialize the NearestNeighbors object with n_neighbors=1 (find the nearest neighbor) \n",
    "        nn1 = NearestNeighbors(n_neighbors=1, algorithm='kd_tree', metric='euclidean')\n",
    "        nn1.fit(coords_Nuclei_physical) #mRNA_Name to Nuclei fit\n",
    "        distances, indices = nn1.kneighbors(coords_edges_Body_physical)\n",
    "        temp_df3 = pd.DataFrame({'z': coords_edges_Body_physical[:, 0], 'y': coords_edges_Body_physical[:, 1], 'x': coords_edges_Body_physical[:, 2], 'distance': distances.flatten()}) # Create a pandas dataframe to store the results\n",
    "        max_distance_from_nuclei = temp_df3['distance'].max()\n",
    "\n",
    "        \n",
    "        median_distance = 0\n",
    "        median_distance_normalized = 0\n",
    " \n",
    "        # Calculate distances from overlap centroids to the nearest nuclei pixel\n",
    "        if overlap_centroids and len(coords_Nuclei_physical) > 0:\n",
    "            overlap_centroids_array = np.array(overlap_centroids)\n",
    "            nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(coords_Nuclei_physical)\n",
    "            distancesNN, indices = nbrs.kneighbors(overlap_centroids_array)\n",
    "\n",
    "            min_distances = [] # list to store min distances\n",
    "            min_distances_normalized = [] # list to store min distances            \n",
    "            \n",
    "            for i, overlap_coord in enumerate(overlap_centroids):\n",
    "                nuclei_coord = coords_Nuclei_physical[indices[i][0]]\n",
    "                min_distance = distancesNN[i][0]\n",
    "                overlap_to_nuclei_distances[overlap_coord] = {'nuclei_coordinates': tuple(nuclei_coord), 'distance': min_distance}\n",
    "\n",
    "                min_distances.append(min_distance) # append min distance to the list\n",
    "                min_distances_normalized.append(min_distance / max_distance_from_nuclei) # append min distance to the list\n",
    "\n",
    "            # Calculate the median for min_distances and min_distances_normalized for the current path\n",
    "            median_distance = np.quantile(min_distances, 0.5)\n",
    "            median_distance_normalized = np.quantile(min_distances_normalized, 0.5)\n",
    "\n",
    "            # create a DataFrame with min distances\n",
    "            df_min_distances = pd.DataFrame(min_distances, columns=[os.path.basename(path)])\n",
    "            df_overlap_to_nuclei_distances = pd.concat([df_overlap_to_nuclei_distances, df_min_distances], axis=1) # concatenate along the column\n",
    "            \n",
    "            df_min_distances_normalized = pd.DataFrame(min_distances_normalized , columns=[os.path.basename(path)])\n",
    "            df_overlap_to_nuclei_distances_normalized = pd.concat([df_overlap_to_nuclei_distances_normalized, df_min_distances_normalized], axis=1) # concatenate along the column\n",
    "\n",
    "        # Simulate random distribution of red centroids within the cytosol\n",
    "        cytosol_coords = np.argwhere(cytosol == True)\n",
    "        num_overlap_centroids = len(overlap_centroids)\n",
    "        random_indices = np.random.choice(range(len(cytosol_coords)), num_overlap_centroids)\n",
    "        random_cytosol_coords = cytosol_coords[random_indices]\n",
    "        random_cytosol_coords_physical = random_cytosol_coords * voxel_dims\n",
    "       \n",
    "        # Calculate distances from random centroids to the nearest nuclei pixel\n",
    "        if random_cytosol_coords_physical.size and len(coords_Nuclei_physical) > 0:\n",
    "            nbrs_random = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(coords_Nuclei_physical)\n",
    "            distances_random, indices_random = nbrs_random.kneighbors(random_cytosol_coords_physical)\n",
    "            \n",
    "            min_distances_random = distances_random.flatten()\n",
    "            min_distances_random_normalized = min_distances_random / max_distance_from_nuclei\n",
    "            min_distances_random_raw = min_distances_random\n",
    "            \n",
    "            # Calculate the median for min_distances_random_normalized for the current path\n",
    "            median_distance_random_normalized = np.quantile(min_distances_random_normalized, 0.5)\n",
    "            median_distances_random_raw = np.quantile(min_distances_random_raw, 0.5)\n",
    "            \n",
    "            # create a DataFrame with normalized random min distances\n",
    "            df_min_distances_random_normalized = pd.DataFrame(min_distances_random_normalized, columns=[os.path.basename(path)])\n",
    "            df_random_overlap_to_nuclei_distances_normalized = pd.concat([df_random_overlap_to_nuclei_distances_normalized, df_min_distances_random_normalized], axis=1)  # concatenate along the column\n",
    "            df_min_distances_random_raw = pd.DataFrame(min_distances_random_raw, columns=[os.path.basename(path)])\n",
    "            df_random_overlap_to_nuclei_distances_raw = pd.concat([df_random_overlap_to_nuclei_distances_raw, df_min_distances_random_raw], axis=1)  # concatenate along the column\n",
    "\n",
    "        # Calculate and add the volume of the Body mask to df1\n",
    "        puncta_red_total = len(red_centroids)\n",
    "        puncta_green_total = len(green_centroids)\n",
    "        puncta_overlap_total = len(overlap_centroids)\n",
    "        percent_of_red_overlapped = puncta_overlap_total * 100 / puncta_red_total if puncta_red_total != 0 else 0\n",
    "        percent_of_green_overlapped = puncta_overlap_total * 100 / puncta_green_total if puncta_green_total != 0 else 0\n",
    "        \n",
    "        voxel_volume = x_dim * y_dim * z_dim  # Calculate the volume of a single voxel\n",
    "        cytosol_volume = np.sum(cytosol) * voxel_volume\n",
    "        \n",
    "        df_temp = pd.DataFrame({\n",
    "            f'overlap_absolute_{WORD1}_{WORD2}_{WORD3}': [puncta_overlap_total],\n",
    "            f'overlap_Normalized_{WORD1}_{WORD2}_{WORD3}': [puncta_overlap_total / cytosol_volume],\n",
    "            f'Half_Dist_Membrane_distance_to_nuclei_{WORD2}': [temp_df3['distance'].quantile(0.5)],\n",
    "            f'%of_{WORD1}_overlap_to_{WORD2}_{WORD3}': [percent_of_red_overlapped],\n",
    "            f'%of_{WORD2}_overlap_to_{WORD1}_{WORD3}': [percent_of_green_overlapped],\n",
    "            f'Half_Dist_Overlap_{WORD1}_{WORD2}_distance_to_nuclei_{WORD3}': [median_distance],\n",
    "            f'Half_Dist_Overlap_{WORD1}_{WORD2}_distance_to_nuclei_{WORD3}_normalized': [median_distance_normalized],\n",
    "            f'Half_Dist_Overlap_{WORD1}_{WORD2}_distance_to_nuclei_{WORD3}_raw': [median_distances_random_raw],            \n",
    "            f'Half_Dist_Overlap_{WORD1}_{WORD2}_distance_to_nuclei_{WORD3}_normalized': [median_distance_random_normalized],\n",
    "\n",
    "            \"path\": path\n",
    "        })\n",
    "\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "        \n",
    "        end_time = time.time() # record end time\n",
    "        elapsed_time = end_time - start_time # calculate elapsed timeCalm1\n",
    "        print(f\"Processed {file} in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    df.to_csv(f'Overlap_Analysis_{WORD1}_{WORD2}_{WORD3}.csv')       \n",
    "    df_overlap_to_nuclei_distances.to_csv(fr'Overlap_{WORD1}_{WORD2}_to_Nuclei_Puncta_all_distances_{WORD3}.csv')     \n",
    "    df_overlap_to_nuclei_distances_normalized.to_csv(fr'Overlap_{WORD1}_{WORD2}_to_Nuclei_Puncta_normalized_all_distances_{WORD3}.csv')     \n",
    "    df_random_overlap_to_nuclei_distances_raw.to_csv(fr'random_{WORD1}_{WORD2}_to_Nuclei_Puncta_raw_distances_{WORD3}.csv')     \n",
    "    df_random_overlap_to_nuclei_distances_normalized.to_csv(fr'random_{WORD1}_{WORD2}_to_Nuclei_Puncta_norm_distances_{WORD3}.csv')     \n",
    "    \n",
    "    return df, df_overlap_to_nuclei_distances, df_overlap_to_nuclei_distances_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c296852-3f97-4728-b22f-a5c29813ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_overlap_path_list = get_labeled_overlap_path(\"Calm3\", \"Ryr2\")\n",
    "print(len(labeled_overlap_path_list))\n",
    "Overlap_Calm3_Ryr2_Fig3, Overlap_Dist_Calm3_Ryr2_Fig3, Overlap_Dist_Norm_Calm3_Ryr2_Fig3 = Puncta_Overlap_Processing(labeled_overlap_path_list, \"Calm3\", \"Ryr2\", \"Fig3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d1004-2da0-44b5-9698-b983554b5105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
